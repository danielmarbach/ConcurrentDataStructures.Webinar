<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Concurrent data structures with examples in Azure Service Bus</title>
    <meta name="description" content="Concurrent data structures with examples in Azure Service Bus">
    <meta name="author" content="Daniel Marbach">
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <script src="//code.jquery.com/jquery-1.8.0.js"></script>
    <script src="//code.jquery.com/ui/1.8.23/jquery-ui.js"></script>
    <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.2.1/css/bootstrap-combined.min.css" rel="stylesheet">
    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/night.css" id="theme">
    <link type="text/css" rel="stylesheet" href="fsharp.formatting/styles/style.css" />
    <link type="text/css" rel="stylesheet" href="fsharp.formatting/styles/deedle.css" />
    <link type="text/css" rel="stylesheet" href="css/custom.css" />
    <script src="fsharp.formatting/styles/tips.js" type="text/javascript"></script>
    <!-- For syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">
    <link rel="stylesheet" href="css/fsreveal.css">
    <!-- If the query includes 'print-pdf', include the PDF print sheet -->
    <script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
    </script>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
    <script language="javascript" type="text/javascript">
        function init()
        {
            websocket = new WebSocket("ws://"+window.location.host+"/websocket");
            websocket.onmessage = function(evt) { location.reload(); };
        }
        window.addEventListener("load", init, false);
    </script>
</head>
<body>
    <div class="reveal">
        
        <!-- Any section element inside of this container is displayed as a slide -->
        <div class="slides">
            <section >
<section >
<h3>Concurrent data structures <br /> with examples in Azure Service Bus</h3>
<p><a href="https://www.twitter.com/danielmarbach">@danielmarbach</a><br />
<a href="https://www.planetgeek.ch">www.planetgeek.ch</a></p>
</section>
<section >
<h3>Introduction</h3>
<ul>
<li>The examples in this presentation use the <a href="https://www.nuget.org/packages/WindowsAzure.ServiceBus/">WindowsAzure.ServiceBus</a> approach to illustrate a problem. The package should no longer be used. If you plan to use Azure Service Bus use <a href="https://www.nuget.org/packages/Microsoft.Azure.ServiceBus/">Microsoft.Azure.ServiceBus</a> or even better <a href="https://www.nuget.org/packages/Azure.Messaging.ServiceBus">Azure.Messaging.ServiceBus</a></li>
<li>For brevity and readability <code>ConfigureAwait(false)</code> has been left out and opionated braces placement has been used (You have been warned!)</li>
<li>If you see spelling mistakes, I accept Pull Requests ;)</li>
</ul>
</section>
<section >
<h3>Why am I telling you this?</h3>
<p><img src="images/copy-paste.jpg" alt="Copy Paste" /></p>
</section>
<section >
<blockquote>
<p><strong>Stackoverflow Law</strong>: Good coders borrow, great coders steal. <a href="https://stackoverflow.blog/2020/05/20/good-coders-borrow-great-coders-steal/">The Internet</a></p>
</blockquote>
</section>
</section>
<section >
<section >
<h3>Receive/Complete messages</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">var</span> factory<span class="n">1</span> <span class="o">=</span> await MessagingFactory.CreateAsync(address, settings);
<span class="k">var</span> factory<span class="n">2</span> <span class="o">=</span> await MessagingFactory.CreateAsync(address, settings;
<span class="k">var</span> receiver<span class="n">1</span> <span class="o">=</span> await factory<span class="n">1</span>.CreateMessageReceiverAsync(queueName, ReceiveMode.PeekLock);
<span class="k">var</span> receiver<span class="n">2</span> <span class="o">=</span> await factory<span class="n">2</span>.CreateMessageReceiverAsync(queueName, ReceiveMode.PeekLock);

receiver<span class="n">1</span>.OnMessageAsync(msg <span class="o">=</span><span class="o">&gt;</span> ReceiveMessage(msg, receiver<span class="n">1</span>), <span class="o">.</span><span class="o">.</span>);
receiver<span class="n">2</span>.OnMessageAsync(msg <span class="o">=</span><span class="o">&gt;</span> ReceiveMessage(msg, receiver<span class="n">2</span>), <span class="o">.</span><span class="o">.</span>);

<span class="k">static</span> <span class="k">async</span> Task ReceiveMessage(BrokeredMessage message, MessageReceiver receiver) {
    <span class="c">// process message</span>
    await receiver.CompleteAsync(message.LockToken)
}
</code></pre></td></tr></table>
<ul>
<li>MessagingFactory = Dedicated TCP connection --&gt; faaast!</li>
<li>Every <code>CompleteAsync</code> is a dedicated call to the cloud --&gt; slooow!</li>
</ul>
</section>
<section >
<h3>Can we do better?</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l">1: </span>
<span class="l">2: </span>
<span class="l">3: </span>
<span class="l">4: </span>
<span class="l">5: </span>
<span class="l">6: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">var</span> lockTokensToComplete <span class="o">=</span> <span class="k">new</span> ConcurrentStack&lt;Guid&gt;();

<span class="k">static</span> <span class="k">async</span> Task ReceiveMessage(BrokeredMessage message) {
    <span class="c">// process message</span>
    lockTokensToComplete.Push(message.LockToken);
}
</code></pre></td></tr></table>
<aside class="notes">
Why `ConcurrentStack` instead of `ConcurrentQueue`? Honestly this code predates me. I guess because the stack contains a `TryPopRange` method<br/>
</aside>
</section>
<section >
<h3>We need someone to complete the tokens</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">var</span> tokenSource <span class="o">=</span> <span class="k">new</span> CancellationTokenSource();
<span class="k">var</span> token <span class="o">=</span> tokenSource.Token;

<span class="k">var</span> batchCompletionTask <span class="o">=</span> Task.Run(<span class="k">async</span> () <span class="o">=</span><span class="o">&gt;</span> {
    <span class="k">while</span>(!token.IsCancellationRequested) {
        <span class="k">var</span> lockTokens <span class="o">=</span> <span class="k">new</span> Guid[<span class="n">100</span>];
        <span class="k">int</span> numberOfItems <span class="o">=</span> lockTokensToComplete.TryPopRange(lockTokens)
        <span class="k">if</span>(numberOfItems <span class="o">&gt;</span> <span class="n">0</span>) {
            await receiveClient.CompleteBatchAsync(lockTokens);
        }
        await Task.Delay(TimeSpan.FromSeconds(<span class="n">5</span>), token);
    }
});
</code></pre></td></tr></table>
<aside class="notes">
Under small load, we complete lock tokens in in batches of one to maximum one hundred tokens.<br/>
If we receive only a limited number of messages, the loop might complete messages with their tokens one by one (for example when we receive a message every 6 seconds). But what happens when the load increases?<br/>
When we’d received several hundred messages per seconds our randomly chosen “complete every one-hundredth messages” and then “sleep for five seconds” might turn out to be a suboptimal choice<br/>
https://www.planetgeek.ch/2016/12/05/another-attempt-to-batch-complete-with-azure-service-bus/<br/>
</aside>
</section>
<section >
<h3>Under concurrency, things might spin</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l">1: </span>
<span class="l">2: </span>
<span class="l">3: </span>
<span class="l">4: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">static</span> <span class="k">async</span> Task ReceiveMessage(BrokeredMessage message) {
    <span class="c">// process message</span>
    lockTokensToComplete.Push(message.LockToken);
}
</code></pre></td></tr></table>
<ul>
<li><code>NumberOfReceivers</code> * <code>ConcurrencyPerReceiver</code> will push to the concurrent stack</li>
</ul>
<aside class="notes">
So for example when we’d use 10 receivers with each a concurrency setting of 32 we’d be ending up pushing lock tokens to the concurrent stack from up to 320 simultaneous operations<br/>
</aside>
</section>
<section >
<blockquote>
<p><strong>Are all of the new concurrent collections lock-free?</strong>: ConcurrentQueue<T> and ConcurrentStack<T> are completely lock-free in this way. They will never take a lock, but they may end up spinning and retrying an operation when faced with contention <a href="https://blogs.msdn.microsoft.com/pfxteam/2010/01/26/faq-are-all-of-the-new-concurrent-collections-lock-free/">Old Post</a></p>
</blockquote>
<aside class="notes">
Of course the concurrent data structures are getting improved, still spinning and retrying is something that has to be taken into account<br/>
</aside>
</section>
<section >
<h3>Under load we might not keep up</h3>
<ul>
<li>Concurrent receivers can fill the concurrent stack faster with lock tokens than our completion loop manage to complete</li>
<li>Increased change of lock lost problems under peek lock</li>
</ul>
</section>
<section >
<h3>Let's fix that</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">var</span> completionTasks <span class="o">=</span> <span class="k">new</span> Task[numberOfReceivers];

<span class="k">for</span>(<span class="k">int</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> numberOfReceivers; i+<span class="o">+</span>) {
    completionTasks[i] <span class="o">=</span> Task.Run(() <span class="o">=</span><span class="o">&gt;</span> BatchCompletionLoop());
}

<span class="k">static</span> <span class="k">async</span> Task BatchCompletionLoop() {
    <span class="k">while</span>(!token.IsCancellationRequested) {
        <span class="k">var</span> lockTokens <span class="o">=</span> <span class="k">new</span> Guid[<span class="n">100</span>];
        <span class="k">int</span> numberOfItems <span class="o">=</span> lockTokensToComplete.TryPopRange(lockTokens)
        <span class="k">if</span>(numberOfItems <span class="o">&gt;</span> <span class="n">0</span>) {
            await receiveClient.CompleteBatchAsync(lockTokens);
        }
        await Task.Delay(TimeSpan.FromSeconds(<span class="n">5</span>), token);
    }
}
</code></pre></td></tr></table>
</section>
<section >
<ul>
<li>Contention problem is even worse, multiple background completion operations are competing on the concurrent stack</li>
<li>Same <code>Task.Delay</code> without jitter causes a lot to wake up and potentially not succed, wasting a lot of resources</li>
</ul>
<aside class="notes">
Even if we had jitter latency might make loops align again over time<br/>
https://www.planetgeek.ch/2016/12/14/batch-completion-with-multiple-receivers-on-azure-service-bus/<br/>
</aside>
</section>
<section >
<h3>There is a dragon hiding here</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l">1: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs">await receiveClient.CompleteBatchAsync(lockTokens);
</code></pre></td></tr></table>
<ul>
<li>Complete always on the same receiver</li>
<li>Works with SBMP (NetMessaging) but fails with AMQP as a transport type</li>
</ul>
</section>
<section >
<h3>Surely we can fix that too?</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">var</span> tokensToComplete <span class="o">=</span> <span class="k">new</span> ConcurrentStack&lt;Guid&gt;[numberOfReceivers];
<span class="c">// initialize the concurrent stacks</span>

receiveClient<span class="n">1</span>.OnMessageAsync(message <span class="o">=</span><span class="o">&gt;</span>
    ReceiveMessage(message, tokensToComplete[<span class="n">0</span>]);
<span class="o">.</span><span class="o">.</span><span class="o">.</span>
receiveClientN.OnMessageAsync(message <span class="o">=</span><span class="o">&gt;</span>
    ReceiveMessage(message, tokensToComplete[N<span class="n">-1</span>]);

<span class="k">static</span> <span class="k">async</span> Task ReceiveMessage(BrokeredMessage message,
    ConcurrentStack&lt;Guid&gt; tokensToComplete) {

    <span class="c">// process message</span>
    tokensToComplete.Push(message.LockToken);

}
</code></pre></td></tr></table>
</section>
<section >
<h3>... and the completion</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">for</span>(<span class="k">int</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> numberOfReceivers; i+<span class="o">+</span>) {
    completionTasks[i] <span class="o">=</span> Task.Run(() <span class="o">=</span><span class="o">&gt;</span>
        BatchCompletionLoop(receivers[i], lockTokensToComplete[i]));
}

<span class="k">static</span> <span class="k">async</span> Task BatchCompletionLoop(MessageReceiver receiver,
    ConcurrentStack&lt;Guid&gt; lockTokensToComplete) {

    <span class="k">while</span>(!token.IsCancellationRequested) {
        <span class="k">var</span> lockTokens <span class="o">=</span> <span class="k">new</span> Guid[<span class="n">100</span>];
        <span class="k">int</span> numberOfItems <span class="o">=</span> lockTokensToComplete.TryPopRange(lockTokens)
        <span class="k">if</span>(numberOfItems <span class="o">&gt;</span> <span class="n">0</span>) {
            await receiver.CompleteBatchAsync(lockTokens);
        }
        await Task.Delay(TimeSpan.FromSeconds(<span class="n">5</span>), token);
    }
}
</code></pre></td></tr></table>
</section>
<section >
<h3>What have we achieved?</h3>
<ul>
<li>Contention is mostly gone</li>
<li>
Completion is guaranteed to use the same receiver to complete
<br/>
<br/>
</li>
</ul>
<h3>but...</h3>
</section>
<section >
<ul>
<li>Still wasting a lot of resources due to the wakeup and idle pattern</li>
<li>Code doesn't really have the necessary elasticity</li>
</ul>
</section>
</section>
<section >
<section >
<h3>Multi Producer Concurrent Consumer</h3>
<ul>
<li>Make sure messages are only completed on the receiver they came from</li>
<li>Reduce the number of threads used when the number of clients is increased</li>
<li>Autoscale up under heavy load</li>
<li>Scale down under light load</li>
<li>Minimise the contention on the underlying collections used</li>
</ul>
</section>
<section >
<ul>
<li>Be completely asynchronous</li>
<li>Implements a push based model from the producer and consumer perspective</li>
<li>Respect the maximum batch sized defined by the client of the component or a predefined push interval</li>
<li>Provide FIFO semantics instead of LIFO</li>
<li>Be as lock-free as possible</li>
</ul>
</section>
<section >
<p><img src="images/mpcc.png" alt="Copy Paste" /></p>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">class</span> MultiProducerConcurrentConsumer&lt;TItem&gt; {
    <span class="k">public</span> MultiProducerConcurrentConsumer(
        <span class="k">int</span> batchSize, TimeSpan pushInterval,
        <span class="k">int</span> maxConcurrency, <span class="k">int</span> numberOfSlots) { }

    <span class="k">public</span> <span class="k">void</span> Start(Func&lt;List&lt;TItem&gt;, <span class="k">int</span>, <span class="k">object</span>, CancellationToken, Task&gt; pump) { }

    <span class="k">public</span> <span class="k">void</span> Start(Func&lt;List&lt;TItem&gt;, <span class="k">int</span>, <span class="k">object</span>, CancellationToken, Task&gt; pump, <span class="k">object</span> state) { }

    <span class="k">public</span> <span class="k">void</span> Push(TItem item, <span class="k">int</span> slotNumber) { }

    <span class="k">public</span> <span class="k">async</span> Task Complete(<span class="k">bool</span> drain <span class="o">=</span> <span class="k">true</span>) { }
}
</code></pre></td></tr></table>
<aside class="notes">
https://www.planetgeek.ch/2017/01/17/introduction-to-the-multiproducerconcurrentconsumer-for-azure-service-bus-message-completion/<br/>
</aside>
</section>
<section >
<h3>Pre-allocate and reuse</h3>
<ul>
<li>Allocate as much as you need upfront</li>
<li>Allocate on-demand when you need it</li>
</ul>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">public</span> MultiProducerConcurrentCompletion(<span class="k">int</span> batchSize, TimeSpan pushInterval,
    <span class="k">int</span> maxConcurrency, <span class="k">int</span> numberOfSlots) {

    queues <span class="o">=</span> <span class="k">new</span> ConcurrentQueue&lt;TItem&gt;[numberOfSlots];
    <span class="k">for</span> (<span class="k">var</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> numberOfSlots; i+<span class="o">+</span>) {
        queues[i] <span class="o">=</span> <span class="k">new</span> ConcurrentQueue&lt;TItem&gt;();
    }

    <span class="k">var</span> maxNumberOfConcurrentOperationsPossible <span class="o">=</span> numberOfSlots <span class="o">*</span> maxConcurrency;
    pushTasks <span class="o">=</span> <span class="k">new</span> List&lt;Task&gt;(maxNumberOfConcurrentOperationsPossible);

    itemListBuffer <span class="o">=</span> <span class="k">new</span> ConcurrentQueue&lt;List&lt;TItem&gt;<span class="o">&gt;</span>();
    <span class="k">for</span> (<span class="k">var</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> maxNumberOfConcurrentOperationsPossible; i+<span class="o">+</span>) {
        itemListBuffer.Enqueue(<span class="k">new</span> List&lt;TItem&gt;(batchSize));
    }
}
</code></pre></td></tr></table>
<aside class="notes">
The benefit of only allocating when needed is that the memory consumption only grows when it is needed. The downside of this approach is that under highly concurrent scenarios allocating structures in a safe and lock-free way can be tricky.<br/>
https://www.planetgeek.ch/2017/01/19/multiproducerconcurrentconsumer-preallocate-and-reuse/<br/>
</aside>
</section>
<section >
<h3>Let's get started</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">public</span> <span class="k">void</span> Start(Func&lt;List&lt;TItem&gt;, <span class="k">int</span>, <span class="k">object</span>, CancellationToken, Task&gt; pump)
    <span class="o">=</span><span class="o">&gt;</span> Start(pump, <span class="k">null</span>);

<span class="k">public</span> <span class="k">void</span> Start(Func&lt;List&lt;TItem&gt;, <span class="k">int</span>, <span class="k">object</span>, CancellationToken, Task&gt; pump,
    <span class="k">object</span> state) {

    <span class="k">if</span> (started)
        <span class="k">throw</span> <span class="k">new</span> InvalidOperationException(<span class="s">"Already started"</span>);

    tokenSource <span class="o">=</span> <span class="k">new</span> CancellationTokenSource();
    timer <span class="o">=</span> Task.Run(TimerLoop);
    <span class="k">this</span>.pump <span class="o">=</span> pump;
    <span class="k">this</span>.state <span class="o">=</span> state;
    started <span class="o">=</span> <span class="k">true</span>;
}
</code></pre></td></tr></table>
<ul>
<li>State based overload helps to avoid closure capturing</li>
</ul>
</section>
<section >
<h3>It's time to push</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">async</span> Task TimerLoop() {
    <span class="k">var</span> token <span class="o">=</span> tokenSource.Token;
    <span class="k">while</span> (!tokenSource.IsCancellationRequested) {
        <span class="k">try</span> {
            await Task.Delay(pushInterval, token);
            await PushInBatches();
        }
        <span class="k">catch</span> (Exception) {
            <span class="c">// intentionally ignored</span>
        }
    }
}
</code></pre></td></tr></table>
<ul>
<li>Achievement: Push items in batches based on the push interval</li>
</ul>
<aside class="notes">
https://www.planetgeek.ch/2017/01/31/multiproducerconcurrentconsumer-start-it/<br/>
</aside>
</section>
<section >
<h3>Push it real good</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">public</span> <span class="k">void</span> Push(TItem item, <span class="k">int</span> slotNumber) {
    <span class="k">if</span> (slotNumber <span class="o">&gt;</span><span class="o">=</span> numberOfSlots)
        <span class="k">throw</span> <span class="k">new</span> ArgumentOutOfRangeException(<span class="o">.</span><span class="o">.</span><span class="o">.</span>);

    queues[slotNumber].Enqueue(item);

    <span class="k">var</span> incrementedCounter <span class="o">=</span> Interlocked.Increment(<span class="k">ref</span> numberOfPushedItems);

    <span class="k">if</span> (incrementedCounter <span class="o">&gt;</span> batchSize) {
        batchSizeReached.TrySetResult(<span class="k">true</span>);
    }
}
</code></pre></td></tr></table>
<ul>
<li>Simple tradeoff: Global counter to reduce complexity</li>
</ul>
</section>
<section >
<h3>There is enough to push</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">async</span> Task TimerLoop() {
    <span class="k">var</span> token <span class="o">=</span> tokenSource.Token;
    <span class="k">while</span> (!tokenSource.IsCancellationRequested) {
        <span class="k">try</span> {
            await Task.WhenAny(Task.Delay(pushInterval, token), batchSizeReached.Task);
            batchSizeReached.TrySetResult(<span class="k">true</span>);
            batchSizeReached <span class="o">=</span>
                <span class="k">new</span> TaskCompletionSource&lt;<span class="k">bool</span>&gt;(
                    TaskCreationOptions.RunContinuationsAsynchronously);
            await PushInBatches();
        }
        <span class="k">catch</span> (Exception)
        {
            <span class="c">// intentionally ignored</span>
        }
    }
}
</code></pre></td></tr></table>
<aside class="notes">
https://www.planetgeek.ch/2017/02/01/multiproducerconcurrentconsumer-push-it/<br/>
</aside>
</section>
<section >
<h3>Push it in batches</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs">Task PushInBatches() {
    <span class="k">if</span> (Interlocked.Read(<span class="k">ref</span> numberOfPushedItems) <span class="o">=</span><span class="o">=</span> <span class="n">0</span>) {
        <span class="k">return</span> Task.CompletedTask;
    }

    <span class="k">for</span> (<span class="k">var</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> numberOfSlots; i+<span class="o">+</span>) {
        <span class="k">var</span> queue <span class="o">=</span> queues[i];

        PushInBatchesUpToConcurrencyPerQueueForAGivenSlot(queue, i, pushTasks);
    }

    <span class="k">return</span> Task.WhenAll(pushTasks).ContinueWith((t, s) <span class="o">=</span><span class="o">&gt;</span> {
        <span class="k">var</span> tasks <span class="o">=</span> (List&lt;Task&gt;)s;
        tasks.Clear();
    }, pushTasks, TaskContinuationOptions.ExecuteSynchronously);
}
</code></pre></td></tr></table>
</section>
<section >
<h3>Now it gets a little bit crazy</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l">1: </span>
<span class="l">2: </span>
<span class="l">3: </span>
<span class="l">4: </span>
<span class="l">5: </span>
<span class="l">6: </span>
<span class="l">7: </span>
<span class="l">8: </span>
<span class="l">9: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">void</span> PushInBatchesUpToConcurrencyPerQueueForAGivenSlot(ConcurrentQueue&lt;TItem&gt; queue,
    <span class="k">int</span> currentSlotNumber, List&lt;Task&gt; tasks) {
    <span class="k">int</span> numberOfItems;
    <span class="k">var</span> concurrency <span class="o">=</span> <span class="n">1</span>;
    <span class="k">do</span> {
        <span class="c">// magic sauce</span>
    }
    <span class="k">while</span> (numberOfItems <span class="o">=</span><span class="o">=</span> batchSize <span class="o">&amp;</span><span class="o">&amp;</span> concurrency <span class="o">&lt;</span><span class="o">=</span> maxConcurrency);
}
</code></pre></td></tr></table>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
<span class="l">18: </span>
<span class="l">19: </span>
<span class="l">20: </span>
<span class="l">21: </span>
<span class="l">22: </span>
<span class="l">23: </span>
<span class="l">24: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">void</span> PushInBatchesUpToConcurrencyPerQueueForAGivenSlot(ConcurrentQueue&lt;TItem&gt; queue,
    <span class="k">int</span> currentSlotNumber, List&lt;Task&gt; tasks) {
    <span class="k">int</span> numberOfItems;
    <span class="k">var</span> concurrency <span class="o">=</span> <span class="n">1</span>;
    <span class="k">do</span> {
        numberOfItems <span class="o">=</span> <span class="n">0</span>;
        List&lt;TItem&gt; items <span class="o">=</span> <span class="k">null</span>;
        <span class="k">for</span> (<span class="k">var</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> batchSize; i+<span class="o">+</span>) {
            <span class="k">if</span> (!queue.TryDequeue(<span class="k">out</span> <span class="k">var</span> item)) {
                <span class="k">break</span>;
            }

            <span class="k">if</span> (items <span class="o">=</span><span class="o">=</span> <span class="k">null</span> <span class="o">&amp;</span><span class="o">&amp;</span> !itemListBuffer.TryDequeue(<span class="k">out</span> items)) {
                items <span class="o">=</span> <span class="k">new</span> List&lt;TItem&gt;(batchSize);
            }

            items.Add(item);
            numberOfItems+<span class="o">+</span>;
        }

        <span class="c">// more magic sauce</span>
    }
    <span class="k">while</span> (numberOfItems <span class="o">=</span><span class="o">=</span> batchSize <span class="o">&amp;</span><span class="o">&amp;</span> concurrency <span class="o">&lt;</span><span class="o">=</span> maxConcurrency);
}
</code></pre></td></tr></table>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
<span class="l">18: </span>
<span class="l">19: </span>
<span class="l">20: </span>
<span class="l">21: </span>
<span class="l">22: </span>
<span class="l">23: </span>
<span class="l">24: </span>
<span class="l">25: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">void</span> PushInBatchesUpToConcurrencyPerQueueForAGivenSlot(ConcurrentQueue&lt;TItem&gt; queue,
    <span class="k">int</span> currentSlotNumber, List&lt;Task&gt; tasks) {
    <span class="k">int</span> numberOfItems;
    <span class="k">var</span> concurrency <span class="o">=</span> <span class="n">1</span>;
    <span class="k">do</span> {
        <span class="c">// previous magic sauce</span>

        <span class="k">if</span> (numberOfItems <span class="o">&lt;</span><span class="o">=</span> <span class="n">0</span>) {
            <span class="k">return</span>;
        }

        Interlocked.Add(<span class="k">ref</span> numberOfPushedItems, -numberOfItems);
        concurrency+<span class="o">+</span>;
        <span class="k">var</span> task <span class="o">=</span> pump(items, currentSlotNumber, state, tokenSource.Token)
            .ContinueWith(<span class="k">static</span> (t, taskState) <span class="o">=</span><span class="o">&gt;</span>
        {
            <span class="k">var</span> (itemList, itemListBuffer) <span class="o">=</span>
               (ValueTuple&lt;List&lt;TItem&gt;, ConcurrentQueue&lt;List&lt;TItem&gt;<span class="o">&gt;</span><span class="o">&gt;</span>) taskState;
            itemList.Clear();
            itemListBuffer.Enqueue(itemList);
        }, (items, itemListBuffer), TaskContinuationOptions.ExecuteSynchronously);
        tasks.Add(task);
    }
    <span class="k">while</span> (numberOfItems <span class="o">=</span><span class="o">=</span> batchSize <span class="o">&amp;</span><span class="o">&amp;</span> concurrency <span class="o">&lt;</span><span class="o">=</span> maxConcurrency);
}
</code></pre></td></tr></table>
</section>
<section >
<h3>Give me the full picture you damn code cheater</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
<span class="l">18: </span>
<span class="l">19: </span>
<span class="l">20: </span>
<span class="l">21: </span>
<span class="l">22: </span>
<span class="l">23: </span>
<span class="l">24: </span>
<span class="l">25: </span>
<span class="l">26: </span>
<span class="l">27: </span>
<span class="l">28: </span>
<span class="l">29: </span>
<span class="l">30: </span>
<span class="l">31: </span>
<span class="l">32: </span>
<span class="l">33: </span>
<span class="l">34: </span>
<span class="l">35: </span>
<span class="l">36: </span>
<span class="l">37: </span>
<span class="l">38: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="cs"><span class="k">void</span> PushInBatchesUpToConcurrencyPerQueueForAGivenSlot(ConcurrentQueue&lt;TItem&gt; queue,
    <span class="k">int</span> currentSlotNumber, List&lt;Task&gt; tasks) {
    <span class="k">int</span> numberOfItems;
    <span class="k">var</span> concurrency <span class="o">=</span> <span class="n">1</span>;
    <span class="k">do</span> {
        numberOfItems <span class="o">=</span> <span class="n">0</span>;
        List&lt;TItem&gt; items <span class="o">=</span> <span class="k">null</span>;
        <span class="k">for</span> (<span class="k">var</span> i <span class="o">=</span> <span class="n">0</span>; i <span class="o">&lt;</span> batchSize; i+<span class="o">+</span>) {
            <span class="k">if</span> (!queue.TryDequeue(<span class="k">out</span> <span class="k">var</span> item)) {
                <span class="k">break</span>;
            }

            <span class="k">if</span> (items <span class="o">=</span><span class="o">=</span> <span class="k">null</span> <span class="o">&amp;</span><span class="o">&amp;</span> !itemListBuffer.TryDequeue(<span class="k">out</span> items)) {
                items <span class="o">=</span> <span class="k">new</span> List&lt;TItem&gt;(batchSize);
            }

            items.Add(item);
            numberOfItems+<span class="o">+</span>;
        }

        <span class="k">if</span> (numberOfItems <span class="o">&lt;</span><span class="o">=</span> <span class="n">0</span>) {
            <span class="k">return</span>;
        }

        Interlocked.Add(<span class="k">ref</span> numberOfPushedItems, -numberOfItems);
        concurrency+<span class="o">+</span>;
        <span class="k">var</span> task <span class="o">=</span> pump(items, currentSlotNumber, state, tokenSource.Token).ContinueWith(<span class="k">static</span> (t, taskState) <span class="o">=</span><span class="o">&gt;</span>
        {
            <span class="k">var</span> (itemList, itemListBuffer) <span class="o">=</span> (ValueTuple&lt;List&lt;TItem&gt;, ConcurrentQueue&lt;List&lt;TItem&gt;<span class="o">&gt;</span><span class="o">&gt;</span>) taskState;
            itemList.Clear();
            itemListBuffer.Enqueue(itemList);
        }, (items, itemListBuffer), TaskContinuationOptions.ExecuteSynchronously);
        tasks.Add(task);
    }
    <span class="k">while</span> (numberOfItems <span class="o">=</span><span class="o">=</span> batchSize <span class="o">&amp;</span><span class="o">&amp;</span> concurrency <span class="o">&lt;</span><span class="o">=</span> maxConcurrency);
}

' https:<span class="c">//www.planetgeek.ch/2017/03/07/multiproducerconcurrentconsumer-push-in-batches-up-to-concurrency-per-slot/</span>
</code></pre></td></tr></table>
<h3>How on earth would we test this beast?</h3>
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="csharp"><span class="k">public</span> <span class="k">async</span> Task Pushing_for_slots_after_start_works_when_batch_size_is_reached() {
    <span class="k">var</span> receivedItems <span class="o">=</span> <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>[<span class="n">4</span>] {
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
    };

    <span class="k">var</span> countDownEvent <span class="o">=</span> <span class="k">new</span> CountdownEvent(<span class="n">16</span>);

    <span class="c">// choose insanely high push interval</span>
    <span class="k">var</span> completion <span class="o">=</span> <span class="k">new</span> MultiProducerConcurrentCompletion&lt;<span class="k">int</span>&gt;(batchSize: <span class="n">100</span>,
        pushInterval: TimeSpan.FromDays(<span class="n">1</span>), maxConcurrency: <span class="n">4</span>, numberOfSlots: <span class="n">4</span>);

    <span class="c">// Asserts</span>
}
</code></pre></td></tr></table>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
<span class="l">18: </span>
<span class="l">19: </span>
<span class="l">20: </span>
<span class="l">21: </span>
<span class="l">22: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="csharp"><span class="k">public</span> <span class="k">async</span> Task Pushing_for_slots_after_start_works_when_batch_size_is_reached() {
    <span class="c">// Previous arrange</span>

    completion.Start(<span class="k">async</span> (items, slot, state, token) <span class="o">=</span><span class="o">&gt;</span> {
        await Task.Yield();
        receivedItems[slot].Enqueue(<span class="k">new</span> List&lt;<span class="k">int</span>&gt;(items)); <span class="c">// take a copy</span>
        <span class="k">if</span> (!countDownEvent.IsSet)
        {
            countDownEvent.Signal();
        }
    });

    <span class="k">var</span> numberOfItems <span class="o">=</span> await PushConcurrentlyTwoThousandItemsInPackages
        OfFiveHundredIntoFourSlots(completion);

    <span class="c">// we wait for 16 counts and then complete midway</span>
    await Task.Run(() <span class="o">=</span><span class="o">&gt;</span> countDownEvent.Wait(TimeSpan.FromSeconds(<span class="n">5</span>)));

    await completion.Complete();

    Assert.AreEqual(TriangularNumber(numberOfItems), Flatten(receivedItems).Sum(i <span class="o">=</span><span class="o">&gt;</span> i));
}
</code></pre></td></tr></table>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
<span class="l">18: </span>
<span class="l">19: </span>
<span class="l">20: </span>
<span class="l">21: </span>
<span class="l">22: </span>
<span class="l">23: </span>
<span class="l">24: </span>
<span class="l">25: </span>
<span class="l">26: </span>
<span class="l">27: </span>
<span class="l">28: </span>
<span class="l">29: </span>
<span class="l">30: </span>
<span class="l">31: </span>
<span class="l">32: </span>
<span class="l">33: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="csharp"><span class="k">public</span> <span class="k">async</span> Task Pushing_for_slots_after_start_works_when_batch_size_is_reached() {
    <span class="k">var</span> receivedItems <span class="o">=</span> <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>[<span class="n">4</span>] {
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
        <span class="k">new</span> ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>(),
    };

    <span class="k">var</span> countDownEvent <span class="o">=</span> <span class="k">new</span> CountdownEvent(<span class="n">16</span>);

    <span class="c">// choose insanely high push interval</span>
    <span class="k">var</span> completion <span class="o">=</span> <span class="k">new</span> MultiProducerConcurrentCompletion&lt;<span class="k">int</span>&gt;(batchSize: <span class="n">100</span>,
        pushInterval: TimeSpan.FromDays(<span class="n">1</span>), maxConcurrency: <span class="n">4</span>, numberOfSlots: <span class="n">4</span>);

    completion.Start(<span class="k">async</span> (items, slot, state, token) <span class="o">=</span>&gt;s {
        await Task.Yield();
        receivedItems[slot].Enqueue(<span class="k">new</span> List&lt;<span class="k">int</span>&gt;(items)); <span class="c">// take a copy</span>
        <span class="k">if</span> (!countDownEvent.IsSet)
        {
            countDownEvent.Signal();
        }
    });

    <span class="k">var</span> numberOfItems <span class="o">=</span> await PushConcurrentlyTwoThousandItemsInPackages
        OfFiveHundredIntoFourSlots(completion);

    <span class="c">// we wait for 16 counts and then complete midway</span>
    await Task.Run(() <span class="o">=</span><span class="o">&gt;</span> countDownEvent.Wait(TimeSpan.FromSeconds(<span class="n">5</span>)));

    await completion.Complete();

    Assert.AreEqual(TriangularNumber(numberOfItems), Flatten(receivedItems).Sum(i <span class="o">=</span><span class="o">&gt;</span> i));
}
</code></pre></td></tr></table>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l">1: </span>
<span class="l">2: </span>
<span class="l">3: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="csharp"><span class="k">int</span> TriangularNumber(<span class="k">int</span> numberOfItems) {
    <span class="k">return</span> numberOfItems*(numberOfItems <span class="o">+</span> <span class="n">1</span>)/<span class="n">2</span>;
}
</code></pre></td></tr></table>
<p><img src="images/triangular.png" alt="Triangular Number" /></p>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="csharp">IEnumerable&lt;<span class="k">int</span>&gt; Flatten(ConcurrentQueue&lt;List&lt;<span class="k">int</span>&gt;<span class="o">&gt;</span>[] captured) {
    <span class="k">var</span> allCaptured <span class="o">=</span> <span class="k">new</span> List&lt;<span class="k">int</span>&gt;();
    <span class="k">foreach</span> (<span class="k">var</span> queue <span class="k">in</span> captured) {
        <span class="k">foreach</span> (<span class="k">var</span> list <span class="k">in</span> queue.ToArray())
        {
            allCaptured.AddRange(list);
        }
    }
    <span class="k">return</span> allCaptured;
}
</code></pre></td></tr></table>
</section>
<section >
<table class="pre"><tr><td class="lines"><pre class="fssnip"><span class="l"> 1: </span>
<span class="l"> 2: </span>
<span class="l"> 3: </span>
<span class="l"> 4: </span>
<span class="l"> 5: </span>
<span class="l"> 6: </span>
<span class="l"> 7: </span>
<span class="l"> 8: </span>
<span class="l"> 9: </span>
<span class="l">10: </span>
<span class="l">11: </span>
<span class="l">12: </span>
<span class="l">13: </span>
<span class="l">14: </span>
<span class="l">15: </span>
<span class="l">16: </span>
<span class="l">17: </span>
<span class="l">18: </span>
<span class="l">19: </span>
<span class="l">20: </span>
<span class="l">21: </span>
<span class="l">22: </span>
<span class="l">23: </span>
<span class="l">24: </span>
</pre></td>
<td class="snippet"><pre class="fssnip highlighted"><code lang="csharp"><span class="k">static</span> <span class="k">async</span> Task&lt;<span class="k">int</span>&gt; PushConcurrentlyTwoThousandItemsInPackagesOf
    FiveHundredIntoFourSlots(MultiProducerConcurrentCompletion&lt;<span class="k">int</span>&gt; completion)
{
    <span class="k">var</span> t<span class="n">1</span> <span class="o">=</span> Task.Run(() <span class="o">=</span><span class="o">&gt;</span> Parallel.For(<span class="n">1</span>, <span class="n">500</span>, i <span class="o">=</span><span class="o">&gt;</span> {
        completion.Push(slotNumber: <span class="n">0</span>, item: i);
    }));

    <span class="k">var</span> t<span class="n">2</span> <span class="o">=</span> Task.Run(() <span class="o">=</span><span class="o">&gt;</span> Parallel.For(<span class="n">500</span>, <span class="n">1000</span>, i <span class="o">=</span><span class="o">&gt;</span> {
        completion.Push(slotNumber: <span class="n">1</span>, item: i);
    }));

    <span class="k">var</span> t<span class="n">3</span> <span class="o">=</span> Task.Run(() <span class="o">=</span><span class="o">&gt;</span> Parallel.For(<span class="n">1000</span>, <span class="n">1500</span>, i <span class="o">=</span><span class="o">&gt;</span> {
        completion.Push(slotNumber: <span class="n">2</span>, item: i);
    }));

    await Task.WhenAll(t<span class="n">1</span>, t<span class="n">2</span>, t<span class="n">3</span>);

    <span class="k">var</span> numberOfItems <span class="o">=</span> <span class="n">2000</span>;
    <span class="k">for</span> (<span class="k">var</span> i <span class="o">=</span> <span class="n">1500</span>; i <span class="o">&lt;</span> numberOfItems <span class="o">+</span> <span class="n">1</span>; i+<span class="o">+</span>)
    {
        completion.Push(slotNumber: <span class="n">3</span>, item: i);
    }
    <span class="k">return</span> numberOfItems;
}
</code></pre></td></tr></table>
</section>
</section>
<section >
<h2>Recap</h2>
<ul>
<li>With the built-in tools we can already achieve quite nice structures for concurrent programming</li>
<li>Today some of the inner workings could be replaced with <code>System.Threading.Channel</code></li>
<li>I encourage you got go through the tests and the code or even build it yourself from scratch, you'll learn a ton</li>
</ul>
</section>
<section >
<h2>Links</h2>
<ul>
<li><a href="https://www.github.com/danielmarbach/ConcurrentDatastructures.Webinar">GitHub</a></li>
<li><a href="https://www.twitter.com/danielmarbach">Twitter</a></li>
<li><a href="https://danielmarbach.github.io/ConcurrentDataStructures.Webinar">Slides Online</a></li>
</ul>
</section>


        </div>
    </div>
    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>
    <script>
        // Add the nohighlight class and data-noescape attribute to code elements that have already been formatted by FSharp.Formatting
        $('pre.highlighted code').addClass('nohighlight').attr('data-noescape', '');

        // Full list of configuration options available here:
        // https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
            controls: true,
            progress: true,
            history: true,
            center: true,

            transition: 'default', // default/cube/page/concave/zoom/linear/fade/none

            // Parallax scrolling
            // parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
            // parallaxBackgroundSize: '2100px 900px',

            // Optional libraries used to extend on reveal.js
            dependencies: [
                { src: 'lib/js/classList.js', condition: function () { return !document.body.classList; } },
                { src: 'plugin/markdown/marked.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
                { src: 'plugin/markdown/markdown.js', condition: function () { return !!document.querySelector('[data-markdown]'); } },
                { src: 'plugin/highlight/highlight.js', async: true, callback: function () { hljs.initHighlightingOnLoad(); } },
                { src: 'plugin/zoom-js/zoom.js', async: true, condition: function () { return !!document.body.classList; } },
                { src: 'plugin/notes/notes.js', async: true, condition: function () { return !!document.body.classList; } }
            ]
        });

    </script>
</body>
</html>

